epochs: 500
lr: 0.0005

network: 
  checkpoint: ~                   # path to checkpoint or ~
  
  freeze_encoder: True           # True, False
  epoch2unfreeze: 50              # epoch to unfreeze encoder
  save_ckpt_every: 3

  params: 
    type: "Bl_gru"               # Bl_gru, Bl_lstm <- de moment aixo (gru_attention, lstm_attention...)
    teacher_forcing_ratio: 0      # number between 0 and 1
    dropout: 0.2                    # number between 0 and 1
    text_max_len: default         # max number of chr/words in a sentence
    rnn_layers: 2

scheduler: 
  type: ~                         # MultiStepLR or ~     
  milestones: [50, 75, 90]        # milestones for MultiStepLR
  gamma: 0.1                      # gamma for MultiStepLR

optimizer: 
  type: "Adam"                     # Adam, SGD
  weight_decay: 0.0001
  lr: 0.0001

early_stopping:
  metric: "bleu2"                 # loss, bleu, rouge
  patience: 125

datasets:
  type: Data_char                 # Data_char, Data_word
  base_path: '/fhome/gia07/Image_captioning/src/Dataset/'
  augment_imgs: False

  train:
    batch_size: 128
    shuffle: True
    num_workers: 2

  valid:
    batch_size: 130
    shuffle: True
    num_workers: 2

  test:
    batch_size: 130
    shuffle: False
    num_workers: 2

wandb: 
  resume: must
  id: s4yrrl9a